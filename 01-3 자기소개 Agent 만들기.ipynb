{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧠 01-3 자기소개 AI Agent 실습\n",
        "---\n",
        "## 🎯 학습목표\n",
        "- Hugging Face `transformers` 라이브러리를 활용하여 간단한 **텍스트 생성 모델**을 실행할 수 있다.  \n",
        "- LLM을 이용해 **자기소개 문장을 자동 생성**할 수 있다.  \n",
        "- **Prompt 작성 방식에 따라 출력이 어떻게 달라지는지** 경험할 수 있다.  \n",
        "\n",
        "---\n",
        "## 💬 들어가며\n",
        "> 여러분이라면 AI Agent가 자기소개를 대신한다면, 어떤 내용을 포함하고 싶나요?\n",
        "\n",
        "예시:\n",
        "- 이름, 전공, 취미, 관심 분야  \n",
        "- 장래희망, 성격, 가치관 등  \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧩 01-3-1 실습 환경 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ 필수 라이브러리 설치\n",
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "💡 **Tip**\n",
        "- Python 3.9 이상 권장 (3.10~3.11 호환)\n",
        "- IDE: VSCode, Jupyter Notebook, Colab 등  \n",
        "- Colab을 사용할 경우, 반드시 첫 실행 셀에 위 명령어를 입력해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 01-3-2 기본 실습: 영어 자기소개 생성\n",
        "> 영어 모델 GPT-2를 사용하여 자기소개 문장을 자동 생성해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 텍스트 생성 파이프라인 생성\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# 자기소개 프롬프트 입력\n",
        "prompt = \"My name is Hong Gil-dong. I am a student majoring in AI. My hobby is\"\n",
        "result = generator(prompt, max_length=60, num_return_sequences=1)\n",
        "\n",
        "print(\"=== 생성된 영어 자기소개 ===\\n\")\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "📌 **생각해보기**\n",
        "- GPT-2는 문장을 자연스럽게 이어가지만, 문맥 연결이 완벽하지 않을 수 있습니다.  \n",
        "- 영어 문장 완성 능력을 관찰하며 LLM의 생성 특성을 이해해봅시다.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🗣️ 01-3-3 심화 실습: 한국어 자기소개 생성\n",
        "> 한국어 전용 모델 **KoGPT2 (skt/kogpt2-base-v2)** 를 사용하여 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 한국어 텍스트 생성 파이프라인\n",
        "generator = pipeline(\"text-generation\", model=\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# 한국어 프롬프트 입력\n",
        "prompt = \"안녕하세요. 제 이름은 홍길동이고, 인공지능을 전공하고 있습니다. 제 취미는\"\n",
        "result = generator(prompt, max_length=80, num_return_sequences=1)\n",
        "\n",
        "print(\"=== 생성된 한국어 자기소개 ===\\n\")\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 실습에서 확인할 사항\n",
        "- 출력 결과에 **비문, 반복 문장, 불완전 문장**이 포함될 수 있음  \n",
        "- Prompt를 조금만 수정해도 결과가 크게 달라짐  \n",
        "\n",
        "| 프롬프트 | 결과 특징 |\n",
        "|-----------|------------|\n",
        "| “제 취미는” | 불완전 문장으로 끝나는 경우 많음 |\n",
        "| “제 취미는 독서와 음악 감상입니다. 저는” | 자연스럽게 자기소개 이어짐 |\n",
        "| “친구들에게 소개하듯이 자연스럽게 자기소개를 해줘” | 대화체로 변환됨 |\n",
        "\n",
        "➡️ **Prompt 설계가 모델의 출력 품질을 결정합니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 💡 01-3-4 응용 실습 아이디어"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| 상황 | 예시 프롬프트 |\n",
        "|------|----------------|\n",
        "| **면접용** | “면접관에게 인사하는 자기소개를 작성해줘. 진지하고 전문적인 어조로.” |\n",
        "| **친구 소개용** | “친근하고 유머러스한 자기소개를 만들어줘.” |\n",
        "| **SNS 프로필용** | “3문장으로 나를 표현하는 자기소개를 써줘.” |\n",
        "| **이력서용** | “이력서에 적을 자기소개를 형식적으로 작성해줘.” |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"친근하고 유머러스하게 자기소개를 작성해줘.\"\n",
        "result = generator(prompt, max_length=100, num_return_sequences=1)\n",
        "\n",
        "print(\"=== 변형 프롬프트 자기소개 ===\\n\")\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "💬 **활동 제안**\n",
        "조별로 서로 다른 프롬프트를 만들어 실행한 뒤,  \n",
        "“어떤 표현이 가장 자연스러운가?”를 비교해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✅ 학습점검 (Check Point)\n",
        "| 질문 | 정답 |\n",
        "|------|------|\n",
        "| Q1. `pipeline` 함수의 역할은? | 모델과 태스크를 한 줄로 실행하도록 도와주는 고수준 인터페이스 |\n",
        "| Q2. GPT-2와 KoGPT2의 차이점은? | 영어 기반 vs 한국어 기반 사전학습 모델 |\n",
        "| Q3. Prompt를 다르게 주면 결과가 달라지는 이유는? | 모델이 확률적 언어 패턴을 학습했기 때문 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧭 학습정리\n",
        "- Hugging Face `transformers`의 **pipeline**을 이용하면 손쉽게 텍스트 생성 모델을 실행할 수 있다.  \n",
        "- LLM은 **입력 프롬프트의 구조와 어조에 따라 완전히 다른 문장**을 생성한다.  \n",
        "- 오늘 실습은 “AI Agent = 텍스트 입력 → 자율적 응답 → 학습 가능한 시스템” 개념의 출발점이다.  \n",
        "- 다음 차시에서는 **LLM의 구조**와 **Hugging Face Hub 모델 탐색**을 학습한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 참고자료\n",
        "- Hugging Face Docs: https://huggingface.co/docs/transformers  \n",
        "- SKT AI Research, *KoGPT2 Base Model* (2021)  \n",
        "- OpenAI, *GPT-2 Technical Paper* (2019)  \n",
        "- FastCampus AI Bootcamp, *LLM 실습 가이드*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}